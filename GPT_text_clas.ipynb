{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"tpu1vmV38","dataSources":[{"sourceId":9027398,"sourceType":"datasetVersion","datasetId":5430387}],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sudorenkoroma/gpt-text-clas?scriptVersionId=191123269\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom transformers import GPT2Tokenizer, TFGPT2ForSequenceClassification, create_optimizer\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.data import Dataset\nfrom sklearn.metrics import classification_report\nimport os\nimport shutil","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-08-04T08:26:11.228886Z","iopub.execute_input":"2024-08-04T08:26:11.229233Z","iopub.status.idle":"2024-08-04T08:26:46.936558Z","shell.execute_reply.started":"2024-08-04T08:26:11.229201Z","shell.execute_reply":"2024-08-04T08:26:46.935512Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nWARNING: Logging before InitGoogle() is written to STDERR\nE0000 00:00:1722759998.355148      13 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n=== Source Location Trace: === \nlearning/45eac/tfrc/runtime/common_lib.cc:479\nD0804 08:26:38.363231096      13 config.cc:196]                        gRPC EXPERIMENT call_status_override_on_cancellation   OFF (default:OFF)\nD0804 08:26:38.363245699      13 config.cc:196]                        gRPC EXPERIMENT call_v3                                OFF (default:OFF)\nD0804 08:26:38.363249072      13 config.cc:196]                        gRPC EXPERIMENT canary_client_privacy                  ON  (default:ON)\nD0804 08:26:38.363251514      13 config.cc:196]                        gRPC EXPERIMENT capture_base_context                   ON  (default:ON)\nD0804 08:26:38.363253891      13 config.cc:196]                        gRPC EXPERIMENT client_idleness                        ON  (default:ON)\nD0804 08:26:38.363256258      13 config.cc:196]                        gRPC EXPERIMENT client_privacy                         ON  (default:ON)\nD0804 08:26:38.363258619      13 config.cc:196]                        gRPC EXPERIMENT dapper_request_wire_size               OFF (default:OFF)\nD0804 08:26:38.363260899      13 config.cc:196]                        gRPC EXPERIMENT empty_experiment                       OFF (default:OFF)\nD0804 08:26:38.363263082      13 config.cc:196]                        gRPC EXPERIMENT event_engine_client                    OFF (default:OFF)\nD0804 08:26:38.363265277      13 config.cc:196]                        gRPC EXPERIMENT event_engine_dns                       ON  (default:ON)\nD0804 08:26:38.363267474      13 config.cc:196]                        gRPC EXPERIMENT event_engine_listener                  ON  (default:ON)\nD0804 08:26:38.363269737      13 config.cc:196]                        gRPC EXPERIMENT free_large_allocator                   OFF (default:OFF)\nD0804 08:26:38.363271927      13 config.cc:196]                        gRPC EXPERIMENT google_no_envelope_resolver            OFF (default:OFF)\nD0804 08:26:38.363274113      13 config.cc:196]                        gRPC EXPERIMENT http2_stats_fix                        OFF (default:OFF)\nD0804 08:26:38.363276281      13 config.cc:196]                        gRPC EXPERIMENT keepalive_fix                          OFF (default:OFF)\nD0804 08:26:38.363278497      13 config.cc:196]                        gRPC EXPERIMENT keepalive_server_fix                   ON  (default:ON)\nD0804 08:26:38.363280920      13 config.cc:196]                        gRPC EXPERIMENT loas_do_not_prefer_rekey_next_protocol OFF (default:OFF)\nD0804 08:26:38.363283153      13 config.cc:196]                        gRPC EXPERIMENT loas_prod_to_cloud_prefer_pfs_ciphers  OFF (default:OFF)\nD0804 08:26:38.363285397      13 config.cc:196]                        gRPC EXPERIMENT monitoring_experiment                  ON  (default:ON)\nD0804 08:26:38.363287719      13 config.cc:196]                        gRPC EXPERIMENT multiping                              OFF (default:OFF)\nD0804 08:26:38.363289942      13 config.cc:196]                        gRPC EXPERIMENT peer_state_based_framing               OFF (default:OFF)\nD0804 08:26:38.363292179      13 config.cc:196]                        gRPC EXPERIMENT pending_queue_cap                      ON  (default:ON)\nD0804 08:26:38.363294545      13 config.cc:196]                        gRPC EXPERIMENT pick_first_happy_eyeballs              ON  (default:ON)\nD0804 08:26:38.363296824      13 config.cc:196]                        gRPC EXPERIMENT promise_based_client_call              OFF (default:OFF)\nD0804 08:26:38.363298970      13 config.cc:196]                        gRPC EXPERIMENT promise_based_inproc_transport         OFF (default:OFF)\nD0804 08:26:38.363301129      13 config.cc:196]                        gRPC EXPERIMENT promise_based_server_call              OFF (default:OFF)\nD0804 08:26:38.363303411      13 config.cc:196]                        gRPC EXPERIMENT registered_method_lookup_in_transport  ON  (default:ON)\nD0804 08:26:38.363305691      13 config.cc:196]                        gRPC EXPERIMENT rfc_max_concurrent_streams             ON  (default:ON)\nD0804 08:26:38.363308053      13 config.cc:196]                        gRPC EXPERIMENT round_robin_delegate_to_pick_first     ON  (default:ON)\nD0804 08:26:38.363311232      13 config.cc:196]                        gRPC EXPERIMENT rstpit                                 OFF (default:OFF)\nD0804 08:26:38.363313583      13 config.cc:196]                        gRPC EXPERIMENT schedule_cancellation_over_write       OFF (default:OFF)\nD0804 08:26:38.363315958      13 config.cc:196]                        gRPC EXPERIMENT server_privacy                         ON  (default:ON)\nD0804 08:26:38.363318328      13 config.cc:196]                        gRPC EXPERIMENT tcp_frame_size_tuning                  OFF (default:OFF)\nD0804 08:26:38.363320593      13 config.cc:196]                        gRPC EXPERIMENT tcp_rcv_lowat                          OFF (default:OFF)\nD0804 08:26:38.363322762      13 config.cc:196]                        gRPC EXPERIMENT trace_record_callops                   OFF (default:OFF)\nD0804 08:26:38.363324982      13 config.cc:196]                        gRPC EXPERIMENT unconstrained_max_quota_buffer_size    OFF (default:OFF)\nD0804 08:26:38.363327279      13 config.cc:196]                        gRPC EXPERIMENT v3_backend_metric_filter               OFF (default:OFF)\nD0804 08:26:38.363329519      13 config.cc:196]                        gRPC EXPERIMENT v3_channel_idle_filters                ON  (default:ON)\nD0804 08:26:38.363331821      13 config.cc:196]                        gRPC EXPERIMENT v3_compression_filter                  ON  (default:ON)\nD0804 08:26:38.363334097      13 config.cc:196]                        gRPC EXPERIMENT v3_server_auth_filter                  OFF (default:OFF)\nD0804 08:26:38.363336306      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_clears_time_cache      OFF (default:OFF)\nD0804 08:26:38.363338467      13 config.cc:196]                        gRPC EXPERIMENT work_serializer_dispatch               OFF (default:OFF)\nD0804 08:26:38.363340709      13 config.cc:196]                        gRPC EXPERIMENT write_size_cap                         ON  (default:ON)\nD0804 08:26:38.363343059      13 config.cc:196]                        gRPC EXPERIMENT write_size_policy                      ON  (default:ON)\nD0804 08:26:38.363345352      13 config.cc:196]                        gRPC EXPERIMENT wrr_delegate_to_pick_first             ON  (default:ON)\nI0804 08:26:38.363514063      13 ev_epoll1_linux.cc:123]               grpc epoll fd: 60\nD0804 08:26:38.363525817      13 ev_posix.cc:113]                      Using polling engine: epoll1\nD0804 08:26:38.374007127      13 lb_policy_registry.cc:46]             registering LB policy factory for \"priority_experimental\"\nD0804 08:26:38.374018119      13 lb_policy_registry.cc:46]             registering LB policy factory for \"outlier_detection_experimental\"\nD0804 08:26:38.374025900      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_target_experimental\"\nD0804 08:26:38.374029150      13 lb_policy_registry.cc:46]             registering LB policy factory for \"pick_first\"\nD0804 08:26:38.374032331      13 lb_policy_registry.cc:46]             registering LB policy factory for \"round_robin\"\nD0804 08:26:38.374035172      13 lb_policy_registry.cc:46]             registering LB policy factory for \"weighted_round_robin\"\nD0804 08:26:38.374062085      13 lb_policy_registry.cc:46]             registering LB policy factory for \"grpclb\"\nD0804 08:26:38.374076841      13 dns_resolver_plugin.cc:43]            Using EventEngine dns resolver\nD0804 08:26:38.374091865      13 lb_policy_registry.cc:46]             registering LB policy factory for \"rls_experimental\"\nD0804 08:26:38.374112397      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_manager_experimental\"\nD0804 08:26:38.374119443      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_cluster_impl_experimental\"\nD0804 08:26:38.374122512      13 lb_policy_registry.cc:46]             registering LB policy factory for \"cds_experimental\"\nD0804 08:26:38.374126472      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_override_host_experimental\"\nD0804 08:26:38.374129425      13 lb_policy_registry.cc:46]             registering LB policy factory for \"xds_wrr_locality_experimental\"\nD0804 08:26:38.374135055      13 lb_policy_registry.cc:46]             registering LB policy factory for \"ring_hash_experimental\"\nD0804 08:26:38.374138283      13 certificate_provider_registry.cc:33]  registering certificate provider factory for \"file_watcher\"\nD0804 08:26:38.374167094      13 channel_init.cc:157]                  Filter server-auth not registered, but is referenced in the after clause of grpc-server-authz when building channel stack SERVER_CHANNEL\nI0804 08:26:38.376025053      13 ev_epoll1_linux.cc:359]               grpc epoll fd: 62\nI0804 08:26:38.389370547      13 tcp_socket_utils.cc:689]              Disabling AF_INET6 sockets because ::1 is not available.\nI0804 08:26:38.393312815     117 socket_utils_common_posix.cc:452]     Disabling AF_INET6 sockets because ::1 is not available.\nI0804 08:26:38.393370178     117 socket_utils_common_posix.cc:379]     TCP_USER_TIMEOUT is available. TCP_USER_TIMEOUT will be used thereafter\nE0804 08:26:38.398955211     101 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {grpc_status:2, created_time:\"2024-08-04T08:26:38.398938149+00:00\"}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ініціалізація TPU\nresolver = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nstrategy = tf.distribute.TPUStrategy(resolver)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:26:46.938033Z","iopub.execute_input":"2024-08-04T08:26:46.938539Z","iopub.status.idle":"2024-08-04T08:26:55.783776Z","shell.execute_reply.started":"2024-08-04T08:26:46.938508Z","shell.execute_reply":"2024-08-04T08:26:55.78279Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\nINFO:tensorflow:Initializing the TPU system: local\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1722760011.391266      13 service.cc:145] XLA service 0x55cfb48f9c00 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1722760011.391313      13 service.cc:153]   StreamExecutor device (0): TPU, 2a886c8\nI0000 00:00:1722760011.391317      13 service.cc:153]   StreamExecutor device (1): TPU, 2a886c8\nI0000 00:00:1722760011.391320      13 service.cc:153]   StreamExecutor device (2): TPU, 2a886c8\nI0000 00:00:1722760011.391323      13 service.cc:153]   StreamExecutor device (3): TPU, 2a886c8\nI0000 00:00:1722760011.391325      13 service.cc:153]   StreamExecutor device (4): TPU, 2a886c8\nI0000 00:00:1722760011.391328      13 service.cc:153]   StreamExecutor device (5): TPU, 2a886c8\nI0000 00:00:1722760011.391331      13 service.cc:153]   StreamExecutor device (6): TPU, 2a886c8\nI0000 00:00:1722760011.391333      13 service.cc:153]   StreamExecutor device (7): TPU, 2a886c8\n","output_type":"stream"},{"name":"stdout","text":"INFO:tensorflow:Finished initializing TPU system.\nINFO:tensorflow:Found TPU system:\nINFO:tensorflow:*** Num TPU Cores: 8\nINFO:tensorflow:*** Num TPU Workers: 1\nINFO:tensorflow:*** Num TPU Cores Per Worker: 8\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:0, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:1, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:2, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:3, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:4, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:5, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:6, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU:7, TPU, 0, 0)\nINFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the dataset\nfile_path = '/kaggle/input/toxic-dataset/combined_train_big.csv'\ndata = pd.read_csv(file_path)\n\n# Preprocess the dataset\ntrain_texts, val_texts, train_labels, val_labels = train_test_split(\n    data['comment_text'].tolist(),\n    data[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].values.tolist(),\n    test_size=0.1\n)\n\n# Tokenizer\ntokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n\n# Add pad token and set padding side to left\ntokenizer.add_special_tokens({'pad_token': '[PAD]'})\ntokenizer.padding_side = \"left\"\n\n# Tokenize function\nMAX_LENGTH = 512\n\ndef tokenize_texts(texts, labels, tokenizer, max_length=MAX_LENGTH):\n    input_ids = []\n    attention_masks = []\n    for text in texts:\n        encoding = tokenizer.encode_plus(\n            text,\n            add_special_tokens=True,\n            max_length=max_length,\n            return_token_type_ids=False,\n            padding='max_length',\n            return_attention_mask=True,\n            truncation=True\n        )\n        input_ids.append(encoding['input_ids'])\n        attention_masks.append(encoding['attention_mask'])\n\n    return (\n        np.array(input_ids),\n        np.array(attention_masks),\n        np.array(labels)\n    )\n\n# Tokenize the datasets\ntrain_input_ids, train_attention_masks, train_labels = tokenize_texts(train_texts, train_labels, tokenizer)\nval_input_ids, val_attention_masks, val_labels = tokenize_texts(val_texts, val_labels, tokenizer)\n\n# Create TensorFlow datasets\ndef create_tf_dataset(input_ids, attention_masks, labels, batch_size=16):\n    dataset = Dataset.from_tensor_slices(({'input_ids': input_ids, 'attention_mask': attention_masks}, labels))\n    dataset = dataset.shuffle(buffer_size=len(input_ids)).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n    return dataset\n\nBATCH_SIZE = 32\n\ntrain_dataset = create_tf_dataset(train_input_ids, train_attention_masks, train_labels, BATCH_SIZE)\nval_dataset = create_tf_dataset(val_input_ids, val_attention_masks, val_labels, BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:26:55.784894Z","iopub.execute_input":"2024-08-04T08:26:55.78515Z","iopub.status.idle":"2024-08-04T08:29:34.617996Z","shell.execute_reply.started":"2024-08-04T08:26:55.785124Z","shell.execute_reply":"2024-08-04T08:29:34.616757Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"from sklearn.utils.class_weight import compute_class_weight\n#  Мітки\ny_train = data.iloc[:, 2:]\n\n# Ініціалізація словника для ваг класів\nclass_weights_dict = {}\n\n# Обчислення ваг для кожного класу\nfor i, column in enumerate(y_train.columns):\n    class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y_train[column]), y=y_train[column])\n    class_weights_dict[i] = class_weights[1]  # class_weight повертає ваги для обох класів 0 і 1, нас цікавить вага для класу 1","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:29:34.619843Z","iopub.execute_input":"2024-08-04T08:29:34.620116Z","iopub.status.idle":"2024-08-04T08:29:34.888078Z","shell.execute_reply.started":"2024-08-04T08:29:34.620092Z","shell.execute_reply":"2024-08-04T08:29:34.886969Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 20\nwith strategy.scope():\n    # Load pre-trained model\n    base_model = TFGPT2ForSequenceClassification.from_pretrained('gpt2')\n    base_model.resize_token_embeddings(len(tokenizer))\n\n    # Model definition using the last token for prediction\n    input_ids = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='input_ids')\n    attention_mask = tf.keras.Input(shape=(MAX_LENGTH,), dtype=tf.int32, name='attention_mask')\n\n    outputs = base_model.transformer(input_ids, attention_mask=attention_mask)\n    last_token_output = outputs.last_hidden_state[:, -1, :]  # Get the last token's hidden state\n    last_token_output_tanh = tf.keras.activations.tanh(last_token_output) \n    dropout1_output = tf.keras.layers.Dropout(0.3)(last_token_output_tanh)\n    Dense_output = tf.keras.layers.Dense(64, activation='relu')(dropout1_output)\n    final_output = tf.keras.layers.Dense(6, activation='sigmoid')(Dense_output)\n\n    model = tf.keras.Model(inputs=[input_ids, attention_mask], outputs=final_output)\n\n    # Optimizer\n    steps_per_epoch = len(train_texts) // BATCH_SIZE\n    num_train_steps = steps_per_epoch * EPOCHS\n    num_warmup_steps = int(0.1 * num_train_steps)\n    optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=num_warmup_steps, num_train_steps=num_train_steps)\n    loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n\n    # Compilation of the model\n    model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n\n# Define early stopping callback\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss',  # Monitor validation loss\n    patience=3,           # Stop training if no improvement after 3 epochs\n    restore_best_weights=True  # Restore the best model weights found during training\n)\n\ndef train_model():\n    with strategy.scope():\n        # Training\n        history = model.fit(\n            train_dataset,\n            epochs=EPOCHS,\n            validation_data=val_dataset,\n#             class_weight=class_weights_dict,\n            callbacks=[early_stopping]  # Include early stopping callback here\n        )\n\n        # Evaluation of the model\n        val_loss, val_acc = model.evaluate(val_dataset)\n        print(f'Validation loss: {val_loss} accuracy: {val_acc}')\n\ntrain_model()","metadata":{"execution":{"iopub.status.busy":"2024-08-04T08:29:34.889307Z","iopub.execute_input":"2024-08-04T08:29:34.889617Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"I0000 00:00:1722760176.766727      13 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\nAll PyTorch model weights were used when initializing TFGPT2ForSequenceClassification.\n\nSome weights or buffers of the TF 2.0 model TFGPT2ForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['score.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/20\n","output_type":"stream"},{"name":"stderr","text":"2024-08-04 08:30:55.001226: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node Adam/AssignAddVariableOp.\nI0000 00:00:1722760257.927019     814 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(a970e06d9437619c:0:0), session_name()\nI0000 00:00:1722760287.201418     814 tpu_compile_op_common.cc:245] Compilation of a970e06d9437619c:0:0 with session name  took 29.274338671s and succeeded\nI0000 00:00:1722760287.272448     814 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(a970e06d9437619c:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_9218482349578203974\", property.function_library_fingerprint = 7450172369679775796, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"4,512,;4,512,;4,6,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1722760287.272505     814 tpu_compilation_cache_interface.cc:541] After adding entry for key a970e06d9437619c:0:0 with session_name  cache is 1 entries (198733058 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"6287/6288 [============================>.] - ETA: 0s - loss: 0.1196 - accuracy: 0.7085","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1722761068.506213     782 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(5e80787426413bd9:0:0), session_name()\nI0000 00:00:1722761093.998878     782 tpu_compile_op_common.cc:245] Compilation of 5e80787426413bd9:0:0 with session name  took 25.492609156s and succeeded\nI0000 00:00:1722761094.067406     782 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(5e80787426413bd9:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_train_function_9218482349578203974\", property.function_library_fingerprint = 7450172369679775796, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"2,512,;2,512,;2,6,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1722761094.067464     782 tpu_compilation_cache_interface.cc:541] After adding entry for key 5e80787426413bd9:0:0 with session_name  cache is 2 entries (383823331 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"6288/6288 [==============================] - ETA: 0s - loss: 0.1196 - accuracy: 0.7086","output_type":"stream"},{"name":"stderr","text":"2024-08-04 08:45:03.220449: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node AssignAddVariableOp.\nI0000 00:00:1722761103.863886     765 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(1d6785ab8bc6aeb0:0:0), session_name()\nI0000 00:00:1722761107.213517     765 tpu_compile_op_common.cc:245] Compilation of 1d6785ab8bc6aeb0:0:0 with session name  took 3.349573089s and succeeded\nI0000 00:00:1722761107.233025     765 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(1d6785ab8bc6aeb0:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_13331886682621282541\", property.function_library_fingerprint = 5134677829110247893, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"4,512,;4,512,;4,6,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1722761107.233067     765 tpu_compilation_cache_interface.cc:541] After adding entry for key 1d6785ab8bc6aeb0:0:0 with session_name  cache is 3 entries (431768754 bytes),  marked for eviction 0 entries (0 bytes).\nI0000 00:00:1722761128.566420     836 tpu_compilation_cache_interface.cc:441] TPU host compilation cache miss: cache_key(ea753e0cb57eb2bb:0:0), session_name()\nI0000 00:00:1722761131.944284     836 tpu_compile_op_common.cc:245] Compilation of ea753e0cb57eb2bb:0:0 with session name  took 3.377826117s and succeeded\nI0000 00:00:1722761131.962258     836 tpu_compilation_cache_interface.cc:475] TPU host compilation cache: compilation complete for cache_key(ea753e0cb57eb2bb:0:0), session_name(), subgraph_key(std::string(property.function_name) = \"cluster_test_function_13331886682621282541\", property.function_library_fingerprint = 5134677829110247893, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, std::string(property.shapes_prefix) = \"3,512,;3,512,;3,6,;\", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = \"1688352644216761960\")\nI0000 00:00:1722761131.962292     836 tpu_compilation_cache_interface.cc:541] After adding entry for key ea753e0cb57eb2bb:0:0 with session_name  cache is 4 entries (480013792 bytes),  marked for eviction 0 entries (0 bytes).\n","output_type":"stream"},{"name":"stdout","text":"6288/6288 [==============================] - 928s 134ms/step - loss: 0.1196 - accuracy: 0.7086 - val_loss: 0.0615 - val_accuracy: 0.9951\nEpoch 2/20\n6288/6288 [==============================] - 804s 128ms/step - loss: 0.0514 - accuracy: 0.8853 - val_loss: 0.0471 - val_accuracy: 0.8389\nEpoch 3/20\n6288/6288 [==============================] - 803s 128ms/step - loss: 0.0443 - accuracy: 0.9008 - val_loss: 0.0448 - val_accuracy: 0.9941\nEpoch 4/20\n6288/6288 [==============================] - 803s 128ms/step - loss: 0.0396 - accuracy: 0.8908 - val_loss: 0.0427 - val_accuracy: 0.9881\nEpoch 5/20\n6288/6288 [==============================] - 802s 128ms/step - loss: 0.0358 - accuracy: 0.9072 - val_loss: 0.0445 - val_accuracy: 0.9888\nEpoch 6/20\n6288/6288 [==============================] - 803s 128ms/step - loss: 0.0323 - accuracy: 0.8212 - val_loss: 0.0459 - val_accuracy: 0.9777\nEpoch 7/20\n3481/6288 [===============>..............] - ETA: 5:47 - loss: 0.0283 - accuracy: 0.8033","output_type":"stream"}]},{"cell_type":"code","source":"predictions = []\ntrue_labels = []\n\nfor batch in val_dataset:\n    input_ids = batch[0]['input_ids']\n    attention_mask = batch[0]['attention_mask']\n    labels = batch[1]\n\n    preds = model.predict({'input_ids': input_ids, 'attention_mask': attention_mask}, verbose=0)\n\n    predictions.extend(preds)\n    true_labels.extend(labels.numpy())\n\npredictions = np.array(predictions)\ntrue_labels = np.array(true_labels)\n\n# Binarize predictions\npredictions = np.where(predictions > 0.4, 1, 0)\n\n# Print classification report\nreport = classification_report(true_labels, predictions, target_names=['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], zero_division=0)\nprint(report)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-04T10:16:08.601079Z","iopub.execute_input":"2024-08-04T10:16:08.601823Z","iopub.status.idle":"2024-08-04T10:22:40.909874Z","shell.execute_reply.started":"2024-08-04T10:16:08.601779Z","shell.execute_reply":"2024-08-04T10:22:40.908869Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"               precision    recall  f1-score   support\n\n        toxic       0.74      0.83      0.78      2192\n severe_toxic       0.51      0.37      0.43       205\n      obscene       0.79      0.84      0.81      1215\n       threat       0.52      0.50      0.51        48\n       insult       0.67      0.80      0.73      1106\nidentity_hate       0.50      0.68      0.58       198\n\n    micro avg       0.72      0.80      0.76      4964\n    macro avg       0.62      0.67      0.64      4964\n weighted avg       0.72      0.80      0.75      4964\n  samples avg       0.07      0.08      0.07      4964\n\n","output_type":"stream"}]}]}